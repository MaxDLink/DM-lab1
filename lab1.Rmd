---
Title: Data Mining Lab 1
Authors: Max Link, Logan Lu, Jadon Klipsch
Date: 2025-02-21
Description: In this project, we will focus on cleaning and understanding the data. We will follow the Crisp-DM framework 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r} 
# Load required libraries
library(dplyr)      # For data manipulation
library(ggplot2)    # For visualizations
library(tidyr)      # For cleaning data
```
```{r dataframe}
# reading in Mobility Report
mobility_data <- read.csv('COVID-19/Global_Mobility_Report.csv')
texas_cases <- read.csv('COVID-19/COVID-19_cases_TX.csv') 
cases_plus <- read.csv('COVID-19/COVID-19_cases_plus_census.csv')

# displaying first 20 rows of report
head(mobility_data, 20)

# texas cases 
head(texas_cases, 20)
# + cases 
head(cases_plus, 20)
```

Crisp-DM Framework:

1. Problem Description (Business Understanding) [10]
Describe the Problem: What is COVID-19, and what is social distancing and flattening the
curve? Why is it important to look at data about the virus spread, hospitalizations, and
available resources? [3 points]

COVID-19 is a highly contagious respiratory illness caused by the SARS-CoV-2 virus, first identified in late 2019. Social distancing involves reducing physical interactions to slow the virus’s spread, aiming to "flatten the curve"—i.e., reduce the peak number of cases to avoid overwhelming healthcare systems. Analyzing data on virus spread, hospitalizations, and resources is critical to understand transmission patterns, predict healthcare demands, and develop effective interventions (e.g., vaccines or supplies by Johnson & Johnson). 

Choose a stakeholder for whom you analyze and, later on, model the data. Define some
questions that are important for this stakeholder. What decisions can your stakeholders make, and how would they affect COVID-19 outcomes? Brainstorm this a lot since this choice will guide your exploration of this and all the following projects. Make sure you can produce actionable recommendations for these questions using your data later in your report. [7 point]

Johnson & Johnson (J&J), a medical company focused on pharmaceuticals, medical devices, and consumer health products.

Questions for J&J:

1. How does population density affect COVID-19 transmission rates across U.S. counties?

2. What is the relationship between social distancing compliance (mobility changes) and case growth?

3. How do hospital resources (e.g., beds per capita) correlate with mortality rates?

4. Which counties showed delayed social distancing responses, and how did this impact case surges?

5. What demographic or geographic factors predict higher demand for medical supplies or vaccines? 

Johnson and Johnson can make the following decisions:

- Prioritize vaccine or medical supply distribution to high-risk, densely populated areas.

- Partner with counties lacking resources to provide equipment or therapeutics.

- Adjust production timelines based on predicted surges linked to mobility patterns.


 2. Data Understanding [45]
 
# Must include all three provided datasets in your analysis!

Describe what data is available. Choose 5-10 important variables for the questions you have identified in the section above. Describe the type of data (scale, values, etc.) of the most critical variables in the data. [9 point]

Data Available: 

1. Global_Mobility_Report.csv: [insert info]  

2. COVID-19 Case Data (hypothetical):  [insert info]  

3. County Resources Data (hypothetical): [insert info]  

# Questions to answer: 

1. How does population density affect COVID-19 transmission rates across U.S. counties?

2. What is the relationship between social distancing compliance (mobility changes) and case growth?

3. How do hospital resources (e.g., beds per capita) correlate with mortality rates?

4. Which counties showed delayed social distancing responses, and how did this impact case surges?

5. What demographic or geographic factors predict higher demand for medical supplies or vaccines? 


# 10 important variables (critical *): 

1. Median_Income (cases_plus.csv): Explore how income levels correlate with Covid-19 cases or deaths, addressing "How does income affect covid status?" 

2. Race_Population (cases_plus.csv): Does race affect covid status? Are there racial disparities in the data? 

3. County_Name (texas_cases.csv) or County, State (cases_plus.csv): Compare urban vs rural counties & their impact on covid-19 status. City vs country 

4. Public_Transportation_Users (cases_plus.csv): Does higher public transit use correlates with higher case rates? 

5. Parents_in_labor_force (cases_plus.csv): Does parental labor force participation influences transmission rates? 

* 6. confirmed_cases (texas_cases.csv or cases_plus.csv): Primary outcome variable to measure infection rates across other ?s  

* 7.Deaths (texas_cases.csv or cases_plus.csv): Critical variable to assess mortality/severity of Covid-19  

8. Rent (cases_plus.csv): proxy for housing cost & potential overcrowding, which could affect transmission risk 

9. Year_House_Built (cases_plus.csv): The house age could cause poor ventilation which may affect transmission risk? 

10. Transit_stations_percent_change_from_baseline (mobility_data.csv, if us data included): Links mobility changes at transit hubs to public transportation use & case rates, if geographically compatible with U.S. counties 

# Description of critical variables: 

..... 


Verify data quality: Are there missing values? Duplicate Data? Outliers? Are those mistakes? How can these be fixed? Ensure your report states how much data is removed and how much you have left. [9 Points]


# 1. Check for missing values in mobility_data 

we can use colSums function to count the missing values in each column of the data 

```{r}
missing_mobility <- colSums(is.na(mobility_data))
print("Missing values in mobility_data:")
print(missing_mobility) 
```

We have quite a few missing values in the mobility data, so lets get rid of the rows that contain the missing values. To do this, we can use the na.omit function and then verify by comparing the original mobility data with a cleaned mobility data. 

```{r}
# remove rows that have missing data 
clean_mobility_data <- na.omit(mobility_data)

# verify the number of rows before and after removal 
print(paste("Original number of rows in mobility_data:", nrow(mobility_data)))
print(paste("Number of rows after removing missing values:", nrow(clean_mobility_data)))

# check for missing values again to confirm. This shows zero missing values 
missing_clean_mobility <- colSums(is.na(clean_mobility_data))
print("Missing values in clean_mobility_data:")
print(missing_clean_mobility)

# display the first few rows of the cleaned data 
head(clean_mobility_data)

```
# 2. Check for missing values in texas_cases

```{r}
missing_texas <- colSums(is.na(texas_cases))
print("Missing values in texas_cases:")
print(missing_texas)
```

# 3. Check for missing values in cases_plus 

```{r}
missing_cases_plus <- colSums(is.na(cases_plus))
print("Missing values in cases_plus:")
print(missing_cases_plus)
```
We have 3142 missing values in certain columns. This means that these columns are completely empty because there are 3142 rows in the data. We can completely remove these columns and then prune for columns that only have some missing values like median_rent. 

```{r}
# Get the total number of rows in cases_plus
total_rows <- nrow(cases_plus)

# Count missing values in each column
missing_counts <- colSums(is.na(cases_plus))

# Debug: Print the missing counts to check values
print("Missing value counts in cases_plus:")
print(missing_counts)

# Identify columns with missing values equal to the total number of rows (completely empty)
empty_columns <- names(missing_counts[missing_counts == total_rows])

# Debug: Print the empty columns to verify
print("Columns identified as completely empty:")
print(empty_columns)

# Remove completely empty columns from cases_plus
cases_plus_cleaned <- cases_plus[, !names(cases_plus) %in% empty_columns]

# Verify the number of columns before and after removal
print(paste("Original number of columns in cases_plus:", ncol(cases_plus)))
print(paste("Number of columns after removing empty columns:", ncol(cases_plus_cleaned))) 

# --------- 
# now remove rows with any remaining missing values (e.g., in median_rent, which has 2 NAs)
clean_cases_plus_final <- na.omit(cases_plus_cleaned)

# verify the number of rows before and after each step
print(paste("Original number of rows in cases_plus:", nrow(cases_plus)))
print("empty columns: ", length(empty_columns))
print(paste("Number of rows after removing empty columns:", nrow(cases_plus_cleaned)))
print(paste("Number of rows after removing rows with any remaining missing values:", nrow(clean_cases_plus_final)))

# check for missing values in the final cleaned dataset to confirm
missing_final <- colSums(is.na(clean_cases_plus_final))
print("Missing values in clean_cases_plus_final:")
print(missing_final)

# display the first few rows of the final cleaned dataset
head(clean_cases_plus_final)
```

Give appropriate statistics (range, mode, mean, median, variance, etc.) for the most important variables in these files and describe what they mean or if you find something interesting. [9 points]


Visually explore the chosen attributes appropriately. Provide an interpretation for each graph. Explain why you chose the visualization for each attribute type. [9 points]


Explore relationships between attributes: Look at the attributes and then use cross-tabulation, correlation, group-wise averages, box plots, etc., as appropriate. [9 points]


3. Data Preparation [30]
Create a data set with objects as rows and features as columns. Use as objects counties in the US. The data set must be included in your report. Provide a table in your Word document that shows the data (values) for the first 10 rows for all the features you have selected and/or created. Interesting additional features may be, for example: [30 points]


When was the first case reported?
How (densely) populated is the county?
What resources does a county have (money, hospital)?
What is the social distancing response, and how long did it take after the first case?
You can come up with more critical questions for your chosen stakeholder.


4. Data Preparation [15]
Formulate some recommendations for the questions developed in section 1. based on the results in 2. and 3. Make sure your recommendations are based on data and are actionable for the stakeholder (i.e., the stakeholder has the power to execute the recommendations). [15 points]
